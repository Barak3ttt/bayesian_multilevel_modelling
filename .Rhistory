)
# ---------------------------------------------------------------------------
# 6. Evaluate on `test_binary` ----------------------------------------------
# ---------------------------------------------------------------------------
probs <- colMeans(posterior_linpred(fit, newdata = test_binary, transform = TRUE))
pred_class <- factor(ifelse(probs > 0.5, 1, 0), levels = c(0, 1))
true_class <- test_binary$Binary.Rating
conf_mat <- table(Predicted = pred_class, Actual = true_class)
accuracy  <- sum(diag(conf_mat)) / sum(conf_mat)
precision <- conf_mat["1", "1"] / sum(conf_mat["1", ])
recall    <- conf_mat["1", "1"] / sum(conf_mat[, "1"])
f1_score  <- 2 * precision * recall / (precision + recall)
roc_obj   <- roc(as.numeric(as.character(true_class)), probs)
auc_value <- auc(roc_obj)
# ---------------------------------------------------------------------------
# 7. Report ------------------------------------------------------------------
# ---------------------------------------------------------------------------
print(conf_mat)
# Collect metrics in a tidy data-frame for clearer printing
metrics <- data.frame(
Metric = c("Accuracy", "Precision", "Recall", "F1 Score", "ROC AUC"),
Value  = c(accuracy, precision, recall, f1_score, auc_value)
)
# Round to three decimals and print
print(round(metrics, 3))
# final_model_fit.R
# Fit a Bayesian multilevel logistic regression using the best hyperparameters
# (reads them directly from the uploaded CSV)
# 1. Load libraries (will error if not installed) ----------------------------
library(brms)
library(pROC)
# ---------------------------------------------------------------------------
# 2. Locate the best-params CSV ---------------------------------------------
# ---------------------------------------------------------------------------
# Assuming your working directory is stored in the variable `wd`.
# The CSV is expected in: <wd>/Hyperparameter_Optimization/
if (!exists("wd")) {
wd <- getwd()  # fallback – uses current working directory
message(sprintf("`wd` not found; defaulting to getwd(): %s", wd))
}
hyper.out.dir <- file.path(wd, "Hyperparameter_Optimization")
if (!dir.exists(hyper.out.dir)) {
stop(sprintf("Directory '%s' does not exist – check `wd`.", hyper.out.dir))
}
csv_files <- list.files(hyper.out.dir, pattern = "^best_params_.*\\.csv$", full.names = TRUE)
if (length(csv_files) == 0) {
stop("No 'best_params_*.csv' file found in ", hyper.out.dir)
}
# Pick the newest file (in case multiple exist)
csv_file <- csv_files[order(file.info(csv_files)$mtime, decreasing = TRUE)][1]
message(sprintf("Reading hyperparameters from: %s", basename(csv_file)))
best_params_df <- read.csv(csv_file, stringsAsFactors = FALSE)
# ---------------------------------------------------------------------------
# 3. Extract hyperparameters with sane fallbacks ----------------------------
# ---------------------------------------------------------------------------
get_or <- function(df, name, default) {
if (name %in% names(df)) df[[name]][1] else default
}
sigma_fixed <- get_or(best_params_df, "sigma_fixed", 2.5)
sigma_group <- get_or(best_params_df, "sigma_group", 1.5)
adapt_delta <- get_or(best_params_df, "adapt_delta", 0.95)
iter        <- get_or(best_params_df, "iter", 1500)
warmup      <- floor(iter / 2)
# ---------------------------------------------------------------------------
# 4. Define priors -----------------------------------------------------------
# ---------------------------------------------------------------------------
priors <- c(
prior_string(sprintf("normal(0, %.4f)", sigma_fixed), class = "b"),
prior_string(sprintf("student_t(3, 0, %.4f)", sigma_group), class = "sd")
)
# ---------------------------------------------------------------------------
# 5. Fit model on `train_binary` ---------------------------------------------
# ---------------------------------------------------------------------------
fit <- brm(
formula = bf(
Binary.Rating ~ Current.Ratio +
`Long.term.Debt...Capital` +
Debt.Equity.Ratio +
EBITDA.Margin +
`Operating.Cash.Flow.Per.Share` +
(1 | Sector)
),
data    = train_binary,
family  = bernoulli(link = "logit"),
prior   = priors,
iter    = iter,
warmup  = warmup,
control = list(adapt_delta = adapt_delta, max_treedepth = 12),
cores   = 4,
refresh = 100
)
# ---------------------------------------------------------------------------
# 6. Evaluate on `test_binary` ----------------------------------------------
# ---------------------------------------------------------------------------
probs <- colMeans(posterior_linpred(fit, newdata = test_binary, transform = TRUE))
pred_class <- factor(ifelse(probs > 0.5, 1, 0), levels = c(0, 1))
true_class <- test_binary$Binary.Rating
conf_mat <- table(Predicted = pred_class, Actual = true_class)
accuracy  <- sum(diag(conf_mat)) / sum(conf_mat)
precision <- conf_mat["1", "1"] / sum(conf_mat["1", ])
recall    <- conf_mat["1", "1"] / sum(conf_mat[, "1"])
f1_score  <- 2 * precision * recall / (precision + recall)
roc_obj   <- roc(as.numeric(as.character(true_class)), probs)
auc_value <- auc(roc_obj)
# ---------------------------------------------------------------------------
# 7. Report ------------------------------------------------------------------
# ---------------------------------------------------------------------------
print(conf_mat)
# Build a small data‑frame and round only the numeric column -----------------
metrics <- data.frame(
Metric = c("Accuracy", "Precision", "Recall", "F1 Score", "ROC AUC"),
Value  = c(accuracy, precision, recall, f1_score, auc_value)
)
metrics$Value <- round(metrics$Value, 3)
print(metrics, row.names = FALSE)
# In case you still want individual lines in the console (use cat so they
# always show up in stdout)
cat(sprintf("\nAccuracy : %.3f\n", accuracy))
cat(sprintf("Precision: %.3f\n", precision))
cat(sprintf("Recall   : %.3f\n", recall))
cat(sprintf("F1 Score : %.3f\n", f1_score))
cat(sprintf("ROC AUC  : %.3f\n\n", auc_value))
# 1. Set your working directory to the root of your project
setwd("C:/Users/azorb/PycharmProjects/bmmProject")  # Adjust path if needed
# 2. Initialize Git and connect to GitHub
system("git init")
system("git remote remove origin 2>nul")  # Silently remove old origin if it exists
system("git remote add origin https://github.com/Barak3ttt/bayesian_multilevel_modelling.git")
# 3. Stage all changes, commit, and rename current branch to 'Barak'
system("git add -A")
system("git commit -m \"Logistic BMM Binary Classification with Hyperoptimization\"")
system("git branch -M Barak")
# 4. Push the 'Barak' branch to GitHub and set it as upstream, forcing overwrite
system("git push -u origin Barak --force")
# basic model diagnostics
print(fit)            # quick coefficients & R-hat
summary(fit)          # full convergence stats
bayesplot::mcmc_trace(as.array(fit))   # trace plots if you have bayesplot installed
# posterior predictive check
pp_check(fit)
# loo object for more detail (elpd, Pareto-k, etc.)
l <- loo(fit, cores = 2)
print(l)
## 4. Model checking (3pt)
### a. Prior sensitivity analysis
```{r prior_sensitivity, echo=TRUE, message=FALSE, warning=FALSE}
library(brms)
library(bayesplot)
# 1. Load best hyperparameters from the most recent CSV
hyper.out.dir <- file.path(wd, "Hyperparameter_Optimization")
if (!dir.exists(hyper.out.dir)) {
stop(sprintf("Directory '%s' does not exist – check `wd`.", hyper.out.dir))
}
csv_files <- list.files(hyper.out.dir, pattern = "^best_params_.*\\.csv$", full.names = TRUE)
if (length(csv_files) == 0) {
stop("No 'best_params_*.csv' file found in ", hyper.out.dir)
}
csv_file <- csv_files[order(file.info(csv_files)$mtime, decreasing = TRUE)][1]
message(sprintf("Reading hyperparameters from: %s", basename(csv_file)))
best_params_df <- read.csv(csv_file, stringsAsFactors = FALSE)
# 2. Extract hyperparameters (with defaults as fallback)
get_or <- function(df, name, default) {
if (name %in% names(df)) df[[name]][1] else default
}
sigma_fixed <- get_or(best_params_df, "sigma_fixed", 2.5)
sigma_group <- get_or(best_params_df, "sigma_group", 1.5)
adapt_delta <- get_or(best_params_df, "adapt_delta", 0.95)
iter        <- get_or(best_params_df, "iter", 1500)
warmup      <- floor(iter / 2)
# 3. Define original and alternative priors
orig_priors <- c(
prior_string(sprintf("normal(0, %.4f)", sigma_fixed), class = "b"),
prior_string(sprintf("student_t(3, 0, %.4f)", sigma_group), class = "sd")
)
alt_priors_tight <- c(
prior(normal(0, 1), class = "b"),
prior(student_t(3, 0, sigma_group), class = "sd")
)
alt_priors_wide <- c(
prior(normal(0, 5), class = "b"),
prior(student_t(3, 0, sigma_group), class = "sd")
)
# 4. Fit prior predictive (sample_prior = "only") under each prior set
pp_orig <- brm(
formula       = Binary.Rating ~ Current.Ratio +
`Long.term.Debt...Capital` +
Debt.Equity.Ratio +
EBITDA.Margin +
`Operating.Cash.Flow.Per.Share` +
(1 | Sector),
data          = train_binary,
family        = bernoulli(link = "logit"),
prior         = orig_priors,
sample_prior  = "only",
iter          = iter,
warmup        = warmup,
control       = list(adapt_delta = adapt_delta),
chains        = 4,
cores         = 4,
refresh       = 0
)
pp_tight <- update(pp_orig, prior = alt_priors_tight, sample_prior = "only", refresh = 0)
## 4. Model checking (3pt)
### a. Prior sensitivity analysis
```{r prior_sensitivity, echo=TRUE, message=FALSE, warning=FALSE}
library(brms)
library(bayesplot)
# 1. Load best hyperparameters from the most recent CSV
hyper.out.dir <- file.path(wd, "Hyperparameter_Optimization")
if (!dir.exists(hyper.out.dir)) {
stop(sprintf("Directory '%s' does not exist – check `wd`.", hyper.out.dir))
}
csv_files <- list.files(hyper.out.dir, pattern = "^best_params_.*\\.csv$", full.names = TRUE)
if (length(csv_files) == 0) {
stop("No 'best_params_*.csv' file found in ", hyper.out.dir)
}
csv_file <- csv_files[order(file.info(csv_files)$mtime, decreasing = TRUE)][1]
message(sprintf("Reading hyperparameters from: %s", basename(csv_file)))
best_params_df <- read.csv(csv_file, stringsAsFactors = FALSE)
# 2. Extract hyperparameters (with defaults as fallback)
get_or <- function(df, name, default) {
if (name %in% names(df)) df[[name]][1] else default
}
sigma_fixed <- get_or(best_params_df, "sigma_fixed", 2.5)
sigma_group <- get_or(best_params_df, "sigma_group", 1.5)
adapt_delta <- get_or(best_params_df, "adapt_delta", 0.95)
iter        <- get_or(best_params_df, "iter", 1500)
warmup      <- floor(iter / 2)
# 3. Define original and alternative priors
orig_priors <- c(
prior_string(sprintf("normal(0, %.4f)", sigma_fixed), class = "b"),
prior_string(sprintf("student_t(3, 0, %.4f)", sigma_group), class = "sd")
)
# Use prior_string() with the numeric sigma_group value, not the R symbol
alt_priors_tight <- c(
prior_string("normal(0, 1)", class = "b"),
prior_string(sprintf("student_t(3, 0, %.4f)", sigma_group), class = "sd")
)
alt_priors_wide <- c(
prior_string("normal(0, 5)", class = "b"),
prior_string(sprintf("student_t(3, 0, %.4f)", sigma_group), class = "sd")
)
# 4. Fit prior predictive (sample_prior = "only") under each prior set
pp_orig <- brm(
formula      = Binary.Rating ~ Current.Ratio +
`Long.term.Debt...Capital` +
Debt.Equity.Ratio +
EBITDA.Margin +
`Operating.Cash.Flow.Per.Share` +
(1 | Sector),
data         = train_binary,
family       = bernoulli(link = "logit"),
prior        = orig_priors,
sample_prior = "only",
iter         = iter,
warmup       = warmup,
control      = list(adapt_delta = adapt_delta),
chains       = 4,
cores        = 4,
refresh      = 0
)
pp_tight <- update(pp_orig, prior = alt_priors_tight, sample_prior = "only", refresh = 0)
pp_wide  <- update(pp_orig, prior = alt_priors_wide,  sample_prior = "only", refresh = 0)
# 5. Extract linear predictor draws and plot
lin_orig  <- posterior_linpred(pp_orig,  transform = FALSE)
lin_tight <- posterior_linpred(pp_tight, transform = FALSE)
lin_wide  <- posterior_linpred(pp_wide,  transform = FALSE)
mcmc_areas(as.matrix(lin_orig)[, 1:100],  prob = 0.5) + ggtitle("Original Priors")
## 4. Model checking (3pt)
### a. Prior sensitivity analysis
```{r prior_sensitivity, echo=TRUE, message=FALSE, warning=FALSE}
library(brms)
library(bayesplot)
# 1. Load best hyperparameters from the most recent CSV
hyper.out.dir <- file.path(wd, "Hyperparameter_Optimization")
if (!dir.exists(hyper.out.dir)) {
stop(sprintf("Directory '%s' does not exist – check `wd`.", hyper.out.dir))
}
csv_files <- list.files(hyper.out.dir, pattern = "^best_params_.*\\.csv$", full.names = TRUE)
if (length(csv_files) == 0) {
stop("No 'best_params_*.csv' file found in ", hyper.out.dir)
}
csv_file <- csv_files[order(file.info(csv_files)$mtime, decreasing = TRUE)][1]
message(sprintf("Reading hyperparameters from: %s", basename(csv_file)))
best_params_df <- read.csv(csv_file, stringsAsFactors = FALSE)
# 2. Extract hyperparameters (with defaults as fallback)
get_or <- function(df, name, default) {
if (name %in% names(df)) df[[name]][1] else default
}
sigma_fixed <- get_or(best_params_df, "sigma_fixed", 2.5)
sigma_group <- get_or(best_params_df, "sigma_group", 1.5)
adapt_delta <- get_or(best_params_df, "adapt_delta", 0.95)
iter        <- get_or(best_params_df, "iter", 1500)
warmup      <- floor(iter / 2)
# 3. Define original and alternative priors
orig_priors <- c(
prior_string(sprintf("normal(0, %.4f)", sigma_fixed), class = "b"),
prior_string(sprintf("student_t(3, 0, %.4f)", sigma_group), class = "sd")
)
# Use prior_string() with the numeric sigma_group value, not the R symbol
alt_priors_tight <- c(
prior_string("normal(0, 1)", class = "b"),
prior_string(sprintf("student_t(3, 0, %.4f)", sigma_group), class = "sd")
)
alt_priors_wide <- c(
prior_string("normal(0, 5)", class = "b"),
prior_string(sprintf("student_t(3, 0, %.4f)", sigma_group), class = "sd")
)
# 4. Fit prior predictive (sample_prior = "only") under each prior set
pp_orig <- brm(
formula      = Binary.Rating ~ Current.Ratio +
`Long.term.Debt...Capital` +
Debt.Equity.Ratio +
EBITDA.Margin +
`Operating.Cash.Flow.Per.Share` +
(1 | Sector),
data         = train_binary,
family       = bernoulli(link = "logit"),
prior        = orig_priors,
sample_prior = "only",
iter         = iter,
warmup       = warmup,
control      = list(adapt_delta = adapt_delta),
chains       = 4,
cores        = 4,
refresh      = 0
)
pp_tight <- update(pp_orig, prior = alt_priors_tight, sample_prior = "only", refresh = 0)
pp_wide  <- update(pp_orig, prior = alt_priors_wide,  sample_prior = "only", refresh = 0)
# 5. Extract linear predictor draws, assign names, and plot
# 5.1 Draw posterior_linpred for each prior scenario
lin_orig  <- posterior_linpred(pp_orig,  transform = FALSE)
lin_tight <- posterior_linpred(pp_tight, transform = FALSE)
lin_wide  <- posterior_linpred(pp_wide,  transform = FALSE)
# 5.2 Convert to matrix and give synthetic column names
lin_orig_mat  <- as.matrix(lin_orig)
colnames(lin_orig_mat)  <- paste0("obs", seq_len(ncol(lin_orig_mat)))
lin_tight_mat <- as.matrix(lin_tight)
colnames(lin_tight_mat) <- paste0("obs", seq_len(ncol(lin_tight_mat)))
lin_wide_mat  <- as.matrix(lin_wide)
colnames(lin_wide_mat)  <- paste0("obs", seq_len(ncol(lin_wide_mat)))
# 5.3 Plot the first 100 “observations” under each prior
library(bayesplot)
mcmc_areas(
lin_orig_mat[, 1:100],
prob = 0.5
) + ggtitle("Original Priors")
mcmc_areas(
lin_tight_mat[, 1:100],
prob = 0.5
) + ggtitle("Tighter Priors (Normal(0,1))")
mcmc_areas(
lin_wide_mat[, 1:100],
prob = 0.5
) + ggtitle("Wider Priors (Normal(0,5))")
# 6. Re-fit the original model for posterior predictive check
fit_full <- brm(
formula = Binary.Rating ~ Current.Ratio +
`Long.term.Debt...Capital` +
Debt.Equity.Ratio +
EBITDA.Margin +
`Operating.Cash.Flow.Per.Share` +
(1 | Sector),
data    = train_binary,
family  = bernoulli(link = "logit"),
prior   = orig_priors,
iter    = iter,
warmup  = warmup,
control = list(adapt_delta = adapt_delta, max_treedepth = 12),
chains  = 4,
cores   = 4,
refresh = 0
)
pp_check(fit_full, nsamples = 100) + ggtitle("Posterior Predictive Check – Original Model")
## 4. Model checking (3pt)
### a. Prior sensitivity analysis
```{r prior_sensitivity, echo=TRUE, message=FALSE, warning=FALSE}
library(brms)
library(bayesplot)
library(ggplot2)
# 1. Load best hyperparameters from the most recent CSV
hyper.out.dir <- file.path(wd, "Hyperparameter_Optimization")
if (!dir.exists(hyper.out.dir)) {
stop(sprintf("Directory '%s' does not exist – check `wd`.", hyper.out.dir))
}
csv_files <- list.files(hyper.out.dir, pattern = "^best_params_.*\\.csv$", full.names = TRUE)
if (length(csv_files) == 0) {
stop("No 'best_params_*.csv' file found in ", hyper.out.dir)
}
csv_file <- csv_files[order(file.info(csv_files)$mtime, decreasing = TRUE)][1]
message(sprintf("Reading hyperparameters from: %s", basename(csv_file)))
best_params_df <- read.csv(csv_file, stringsAsFactors = FALSE)
# 2. Extract hyperparameters (with defaults as fallback)
get_or <- function(df, name, default) {
if (name %in% names(df)) df[[name]][1] else default
}
sigma_fixed <- get_or(best_params_df, "sigma_fixed", 2.5)
sigma_group <- get_or(best_params_df, "sigma_group", 1.5)
adapt_delta <- get_or(best_params_df, "adapt_delta", 0.95)
iter        <- get_or(best_params_df, "iter", 1500)
warmup      <- floor(iter / 2)
# 3. Define original and alternative priors
orig_priors <- c(
prior_string(sprintf("normal(0, %.4f)", sigma_fixed), class = "b"),
prior_string(sprintf("student_t(3, 0, %.4f)", sigma_group), class = "sd")
)
alt_priors_tight <- c(
prior_string("normal(0, 1)", class = "b"),
prior_string(sprintf("student_t(3, 0, %.4f)", sigma_group), class = "sd")
)
alt_priors_wide <- c(
prior_string("normal(0, 5)", class = "b"),
prior_string(sprintf("student_t(3, 0, %.4f)", sigma_group), class = "sd")
)
# 4. Fit prior predictive (sample_prior = "only") under each prior set
pp_orig <- brm(
formula      = Binary.Rating ~ Current.Ratio +
`Long.term.Debt...Capital` +
Debt.Equity.Ratio +
EBITDA.Margin +
`Operating.Cash.Flow.Per.Share` +
(1 | Sector),
data         = train_binary,
family       = bernoulli(link = "logit"),
prior        = orig_priors,
sample_prior = "only",
iter         = iter,
warmup       = warmup,
control      = list(adapt_delta = adapt_delta),
chains       = 4,
cores        = 4,
refresh      = 0
)
pp_tight <- update(pp_orig, prior = alt_priors_tight, sample_prior = "only", refresh = 0)
pp_wide  <- update(pp_orig, prior = alt_priors_wide,  sample_prior = "only", refresh = 0)
# 5. Extract linear predictor draws, assign names, and plot
lin_orig_mat  <- as.matrix(posterior_linpred(pp_orig,  transform = FALSE))
colnames(lin_orig_mat)  <- paste0("obs", seq_len(ncol(lin_orig_mat)))
lin_tight_mat <- as.matrix(posterior_linpred(pp_tight, transform = FALSE))
colnames(lin_tight_mat) <- paste0("obs", seq_len(ncol(lin_tight_mat)))
lin_wide_mat  <- as.matrix(posterior_linpred(pp_wide,  transform = FALSE))
colnames(lin_wide_mat)  <- paste0("obs", seq_len(ncol(lin_wide_mat)))
mcmc_areas(
lin_orig_mat[, 1:100],
prob = 0.5
) + labs(title = "Original Priors")
mcmc_areas(
lin_tight_mat[, 1:100],
prob = 0.5
) + labs(title = "Tighter Priors (Normal(0,1))")
mcmc_areas(
lin_wide_mat[, 1:100],
prob = 0.5
) + labs(title = "Wider Priors (Normal(0,5))")
# 6. Re-fit the original model for posterior predictive check
fit_full <- brm(
formula = Binary.Rating ~ Current.Ratio +
`Long.term.Debt...Capital` +
Debt.Equity.Ratio +
EBITDA.Margin +
`Operating.Cash.Flow.Per.Share` +
(1 | Sector),
data    = train_binary,
family  = bernoulli(link = "logit"),
prior   = orig_priors,
iter    = iter,
warmup  = warmup,
control = list(adapt_delta = adapt_delta, max_treedepth = 12),
chains  = 4,
cores   = 4,
refresh = 0
)
pp_check(fit_full, ndraws = 100) + labs(title = "Posterior Predictive Check – Original Model")
# 1. Set your working directory to the root of your project
setwd("C:\Users\azorb\PycharmProjects\bmmProject")  # <<< REPLACE WITH YOUR LOCAL FILE PATH
# Or escape backslashes
setwd("C:\\Users\\azorb\\PycharmProjects\\bmmProject")
# 1. Set your working directory to the root of your project
setwd("C:\Users\azorb\PycharmProjects\bmmProject")  # <<< REPLACE WITH YOUR LOCAL FILE PATH
# 2. Initialize Git and connect to GitHub
system("git init")
system("git remote remove origin 2>nul")  # Silently remove old origin if it exists
system("git remote add origin https://github.com/Barak3ttt/bayesian_multilevel_modelling.git")
# 3. Stage all changes, commit, and rename current branch
system("git add -A")
system("git commit -m \"Added prior sentivitiy analysis\"")  # <<< DESCRIBE YOUR CHANGES
system("git branch -M Barak")             # <<< E.G., YOUR NAME OR TASK
# 4. Push the branch to GitHub and set it as upstream, forcing overwrite
system("git push -u origin Barak--force")  # <<< MATCH THE BRANCH NAME ABOV
# 2. Initialize Git and connect to GitHub
system("git init")
system("git remote remove origin 2>nul")  # Silently remove old origin if it exists
system("git remote add origin https://github.com/Barak3ttt/bayesian_multilevel_modelling.git")
# 3. Stage all changes, commit, and rename current branch
system("git add -A")
system("git commit -m \"Added prior sentivitiy analysis\"")  # <<< DESCRIBE YOUR CHANGES
system("git branch -M Barak")             # <<< E.G., YOUR NAME OR TASK
# 4. Push the branch to GitHub and set it as upstream, forcing overwrite
system("git push -u origin Barak--force")  # <<< MATCH THE BRANCH NAME ABOV
# 2. Initialize Git and connect to GitHub
system("git init")
system("git remote remove origin 2>nul")  # Silently remove old origin if it exists
system("git remote add origin https://github.com/Barak3ttt/bayesian_multilevel_modelling.git")
# 3. Stage all changes, commit, and rename current branch
system("git add -A")
system("git commit -m \"Added prior sentivitiy analysis\"")  # <<< DESCRIBE YOUR CHANGES
system("git branch -M Barak")             # <<< E.G., YOUR NAME OR TASK
# 4. Push the branch to GitHub and set it as upstream, forcing overwrite
system("git push -u origin Barak --force")  # <<< MATCH THE BRANCH NAME ABOV
system("git clone --branch main https://github.com/Barak3ttt/bayesian_multilevel_modelling.git")
system("git clone git@github.com:Barak3ttt/bayesian_multilevel_modelling.git")
system("git clone git@github.com:Barak3ttt/bayesian_multilevel_modelling.git")
